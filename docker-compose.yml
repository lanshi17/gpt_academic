services:
  gpt_academic_with_latex:
    image: ghcr.io/binary-husky/gpt_academic_with_latex:master  # (Auto Built by Dockerfile: docs/GithubAction+NoLocal+Latex)
    # 对于ARM64设备，请将以上镜像名称替换为 ghcr.io/binary-husky/gpt_academic_with_latex_arm:master
    environment:
      # 请查阅 `config.py` 以查看所有的配置信息
      API_KEY: 'sk-1s3ApG63c4aP0EdE2A1anqwhpHvxd25QFmNNjLkoJ8l5jsKW'
      DASHSCOPE_API_KEY: 'sk-9fd4a1a4fefc42048174f9168c7bdd6c'
      SILICONFLOW_API_KEY: 'sk-qqkhvtehvscrwenhzixflzzmmdgzmzaufwurejxgnfbrxcjo'
      API_URL_REDIRECT: |
        {"https://api.openai.com/v1/chat/completions": "https://api.wlai.vip/v1/chat/completions"}
      USE_PROXY: 'False'
      proxies: |
        {
          "http": "socks5h://localhost:10880",
          "https": "socks5h://localhost:10880"
        }
      LLM_MODEL: 'gpt-5.1'
      AVAIL_LLM_MODELS: |
        [
          "gpt-5.1",
          "gemini-3-pro-preview-11-2025",
          "claude-haiku-4-5-20251001",
          "claude-opus-4-1-20250805",
          "claude-sonnet-4-20250514-thinking",
          "claude-sonnet-4-20250514",
          "gpt-5",
          "deepseek-ai/DeepSeek-V3.1-Terminus",
          "deepseek-ai/DeepSeek-OCR",
          "qwen3-max",
          "zai-org/GLM-4.6",
          "grok-4.1",
          "qwen-max",
          "o1-mini",
          "o1-mini-2024-09-12",
          "o1",
          "o1-2024-12-17",
          "o1-preview",
          "o1-preview-2024-09-12",
          "gpt-4-1106-preview",
          "gpt-4-turbo-preview",
          "gpt-4-vision-preview",
          "gpt-4o",
          "gpt-4o-mini",
          "gpt-4-turbo",
          "gpt-4-turbo-2024-04-09",
          "gpt-3.5-turbo-1106",
          "gpt-3.5-turbo-16k",
          "gpt-3.5-turbo",
          "azure-gpt-3.5",
          "gpt-4",
          "gpt-4-32k",
          "azure-gpt-4",
          "glm-4",
          "glm-4v",
          "glm-3-turbo",
          "gemini-1.5-pro",
          "chatglm3",
          "chatglm4",
          "deepseek-chat",
          "deepseek-coder",
          "deepseek-reasoner",
          "volcengine-deepseek-r1-250120",
          "volcengine-deepseek-v3-241226",
          "dashscope-deepseek-r1",
          "dashscope-deepseek-v3",
          "dashscope-qwen3-14b",
          "dashscope-qwen3-235b-a22b",
          "dashscope-qwen3-32b"
        ]
      LOCAL_MODEL_DEVICE: 'cuda'
      DEFAULT_WORKER_NUM: '10'
      WEB_PORT: '12303'

    # 挂载本地代码卷
    volumes:
      - ./request_llms:/gpt/request_llms
      - ./config_private.py:/gpt/config_private.py

    # 「WEB_PORT暴露方法1: 适用于Linux」与宿主的网络融合
    network_mode: "host"

    # 启动命令
    command: >
      bash -c "python3 -u main.py"

